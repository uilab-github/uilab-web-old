<html xmlns:v="urn:schemas-microsoft-com:vml"
xmlns:o="urn:schemas-microsoft-com:office:office"
xmlns:w="urn:schemas-microsoft-com:office:word"
xmlns:m="http://schemas.microsoft.com/office/2004/12/omml"
xmlns="http://www.w3.org/TR/REC-html40">

<head>
<meta http-equiv=Content-Type content="text/html; charset=utf-8">
<meta name=ProgId content=Word.Document>
<meta name=Generator content="Microsoft Word 14">
<meta name=Originator content="Microsoft Word 14">
</head>

<body lang=KO link=blue vlink=purple style='tab-interval:40.0pt'>

<p align=center style='text-align:center'><b style='mso-bidi-font-weight:
normal'><span lang=EN-US style='font-size:20.0pt;mso-bidi-font-size:11.0pt;
line-height:115%'>Self-disclosure topic model for classifying and analyzing Twitter conversations</span></b></p>

<p align=center style='text-align:center'><b style='mso-bidi-font-weight:
normal'><span lang=EN-US style='font-size:12.0pt;mso-bidi-font-size:11.0pt;
line-height:115%'>JinYeong Bak, Chin-Yew Lin and Alice Oh</span></b></p>

<p align=center style='text-align:center'><i style='mso-bidi-font-style:
normal'><span lang=EN-US style='font-size:12.0pt;mso-bidi-font-size:11.0pt;
line-height:115%'>jy.bak@kaist.ac.kr, cyl@microsoft.com, alice.oh@kaist.edu</span></i></p>

<p align=right style='text-align:right'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

<p align=right style='text-align:right'><span lang=EN-US>Empirical Methods in Natural Language Processing (EMNLP 2014)</span></p>

<p><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

<p><b style='mso-bidi-font-weight:normal'><span lang=EN-US>Abstract<o:p></o:p></span></b></p>

<p><span
lang=EN-US>Self-disclosure, the act of revealing oneself to others, is an important social behavior that strengthens interpersonal relationships and increases social support. Although there are many social science studies of self-disclosure, they are based on manual coding of small datasets and  questionnaires. We conduct a computational analysis of self-disclosure with a large dataset of naturally-occurring conversations, a semi-supervised machine learning algorithm, and a computational analysis of the effects of self-disclosure on subsequent conversations.
We use a longitudinal dataset of 17 million tweets, all of which occurred in conversations that consist of five or more tweets directly replying to the previous tweet, and from dyads with twenty of more conversations each. We develop self-disclosure topic model (SDTM), a variant of latent Dirichlet allocation (LDA) for automatically classifying the level of self-disclosure for each tweet. We take the results of SDTM and analyze the effects of self-disclosure on subsequent conversations. Our model significantly outperforms several comparable methods on classifying the level of self-disclosure, and the analysis of the longitudinal data using SDTM uncovers significant and positive correlation between self-disclosure and conversation frequency and length.</span></p>

<p><span
lang=EN-US><o:p>&nbsp;</o:p></span></p>

<p><b
style='mso-bidi-font-weight:normal'><span lang=EN-US>Paper<o:p></o:p></span></b></p>

<p><span lang=EN-US>- <a href="./emnlp2014_bak_lin_oh.pdf">PDF</a></span></p>

<p><span
lang=EN-US><o:p>&nbsp;</o:p></span></p>

<p><b
style='mso-bidi-font-weight:normal'><span lang=EN-US>Slides<o:p></o:p></span></b></p>

<p><span lang=EN-US>- <a href="./EMNLP2014_Slides.pdf">PDF</a></span></p>

<!--<p><span lang=EN-US>- <a href="">Supplementary</a></span></p>-->

<p><span
lang=EN-US><o:p>&nbsp;</o:p></span></p>

<p><b
style='mso-bidi-font-weight:normal'><span lang=EN-US>Source Code and Data<o:p></o:p></span></b></p>

<p><span lang=EN-US>- Source Code (<a href="https://github.com/NoSyu/SDTM">Github</a>)</span></p>

<p><span lang=EN-US>- <a href="./Twitter_Conversation.zip">Data</a></span></p>

<p><span
lang=EN-US><o:p>&nbsp;</o:p></span></p>

<!--
<p><b
style='mso-bidi-font-weight:normal'><span lang=EN-US>Tutorial<o:p></o:p></span></b></p>

<p style='text-indent:40.0pt;mso-char-indent-count:4.0'><b
style='mso-bidi-font-weight:normal'><span lang=EN-US>Requirement<o:p></o:p></span></b></p>

<p style='margin-left:40.0pt;mso-para-margin-left:4.0gd;
text-indent:5.0pt;mso-char-indent-count:.5'><span lang=EN-US>Hadoop 0.20.2</span></p>

<p style='margin-left:40.0pt;mso-para-margin-left:4.0gd;
text-indent:5.0pt;mso-char-indent-count:.5'><span lang=EN-US>Python 2.6</span></p>

<p style='margin-left:40.0pt;mso-para-margin-left:4.0gd;
text-indent:5.0pt;mso-char-indent-count:.5'><span lang=EN-US><a
href="https://github.com/klbostee/dumbo/">dumbo</a>, NumPy, SciPy package</span></p>

<p><span
lang=EN-US><o:p>&nbsp;</o:p></span></p>

<p style='text-indent:40.0pt;mso-char-indent-count:4.0'><b
style='mso-bidi-font-weight:normal'><span lang=EN-US>Start<o:p></o:p></span></b></p>

<p style='margin-left:40.0pt;mso-para-margin-left:4.0gd;
text-indent:5.0pt;mso-char-indent-count:.5'><span lang=EN-US>To run this code,
command is as below.</span></p>

<table class=MsoTableGrid border=1 cellspacing=0 cellpadding=0 width=615
 style='width:461.2pt;margin-left:40.0pt;border-collapse:collapse;border:none;
 mso-border-alt:solid windowtext .5pt;mso-yfti-tbllook:1184;mso-padding-alt:
 0cm 5.4pt 0cm 5.4pt'>
 <tr style='mso-yfti-irow:0;mso-yfti-firstrow:yes;mso-yfti-lastrow:yes'>
  <td width=615 valign=top style='width:461.2pt;border:solid windowtext 1.0pt;
  mso-border-alt:solid windowtext .5pt;padding:0cm 5.4pt 0cm 5.4pt'>
  <p><span lang=EN-US>sh DoLDA.sh word_file_path document_file_path
  topic_num minibatch_size tau0 kappa num_mapper hadoop_hdfs_root</span></p>
  </td>
 </tr>
</table>

<p style='text-indent:40.0pt;mso-char-indent-count:4.0'><b
style='mso-bidi-font-weight:normal'><span lang=EN-US><o:p>&nbsp;</o:p></span></b></p>

<p style='text-indent:40.0pt;mso-char-indent-count:4.0'><b
style='mso-bidi-font-weight:normal'><span lang=EN-US>Argument<o:p></o:p></span></b></p>

<p style='margin-left:40.0pt;mso-para-margin-left:4.0gd;
text-indent:5.0pt;mso-char-indent-count:.5'><span lang=EN-US>word_file_path &#8211;
word file path. String</span></p>

<p style='margin-left:40.0pt;mso-para-margin-left:4.0gd;
text-indent:5.0pt;mso-char-indent-count:.5'><span lang=EN-US>document_file_path
&#8211; document file path. String</span></p>

<p style='margin-left:40.0pt;mso-para-margin-left:4.0gd;
text-indent:5.0pt;mso-char-indent-count:.5'><span lang=EN-US>topic_num &#8211; the
number of topics. Integer</span></p>

<p style='margin-left:40.0pt;mso-para-margin-left:4.0gd;
text-indent:5.0pt;mso-char-indent-count:.5'><span lang=EN-US>minibatch_size &#8211;
the size of mini-batch. Integer</span></p>

<p style='margin-left:40.0pt;mso-para-margin-left:4.0gd;
text-indent:5.0pt;mso-char-indent-count:.5'><span lang=EN-US>tau0 &#8211; parameter
of learning rate. Integer</span></p>

<p style='margin-left:40.0pt;mso-para-margin-left:4.0gd;
text-indent:5.0pt;mso-char-indent-count:.5'><span lang=EN-US>kappa - parameter
of learning rate. Float</span></p>

<p style='margin-left:40.0pt;mso-para-margin-left:4.0gd;
text-indent:5.0pt;mso-char-indent-count:.5'><span lang=EN-US>num_mapper &#8211; the
number of mapper. Integer</span></p>

<p style='margin-left:40.0pt;mso-para-margin-left:4.0gd;
text-indent:5.0pt;mso-char-indent-count:.5'><span lang=EN-US>hadoop_hdfs_root &#8211;
hdfs root path for input and output. Do not include ‘/’ at the end. String</span></p>

<p><span
lang=EN-US><o:p>&nbsp;</o:p></span></p>

<p style='text-indent:40.0pt;mso-char-indent-count:4.0'><b
style='mso-bidi-font-weight:normal'><span lang=EN-US>Example<o:p></o:p></span></b></p>

<table class=MsoTableGrid border=1 cellspacing=0 cellpadding=0 width=615
 style='width:461.2pt;margin-left:40.0pt;border-collapse:collapse;border:none;
 mso-border-alt:solid windowtext .5pt;mso-yfti-tbllook:1184;mso-padding-alt:
 0cm 5.4pt 0cm 5.4pt'>
 <tr style='mso-yfti-irow:0;mso-yfti-firstrow:yes;mso-yfti-lastrow:yes'>
  <td width=615 valign=top style='width:461.2pt;border:solid windowtext 1.0pt;
  mso-border-alt:solid windowtext .5pt;padding:0cm 5.4pt 0cm 5.4pt'>
  <p><span lang=EN-US>sh DoLDA.sh ../Twitter_Conversation/Voca_TC.txt
  ../Twitter_Conversation/BOW_TC.txt 100 16384 1024 0.7 3 hdfs://uilabctr01.kaist.ac.kr:8020/user/hadoop_usr</span></p>
  </td>
 </tr>
</table>

<p style='margin-left:40.0pt;mso-para-margin-left:4.0gd;
text-indent:5.0pt;mso-char-indent-count:.5'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>
-->

<!--
<p><b
style='mso-bidi-font-weight:normal'><span lang=EN-US>Data<o:p></o:p></span></b></p>

<p><span
lang=EN-US>We crawled Twitter for conversations written in English, where a conversation is defined as a sequence of reply tweets by two Twitter users. We only used conversations with five or more tweets, and we defined each conversation as a document. We removed stopwords and words with document frequency of 30 or smaller. The number of documents is 973,266, and the average document length is 7.54 tweets. The size of the vocabulary is 40,927.</span></p>

<p style='text-indent:40.0pt;mso-char-indent-count:4.0'><b
style='mso-bidi-font-weight:normal'><span lang=EN-US>Files<o:p></o:p></span></b></p>

<p style='margin-left:40.0pt;mso-para-margin-left:4.0gd;
text-indent:5.0pt;mso-char-indent-count:.5'><span lang=EN-US>BOW_TC.txt &#8211; Bag of words format of Twitter conversations. Each line is each conversation between two users. Delimiter is space character. First column represents document id, second column represents number of words in a document. Remains are made up wordindex:wordcount in a document. Word index is starting as 0.</span></p>

<p style='margin-left:40.0pt;mso-para-margin-left:4.0gd;
text-indent:5.0pt;mso-char-indent-count:.5'><span lang=EN-US>Voca_TC.txt &#8211; All words in BOW_TC.txt. Each line represents each word. In BOW_TC.txt, word index starts as 0, so word index of first word, twitter, is 0, not 1.</span></p>


<p style='margin-left:40.0pt;mso-para-margin-left:4.0gd;
text-indent:5.0pt;mso-char-indent-count:.5'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>
-->

<!--
<p><b
style='mso-bidi-font-weight:normal'><span lang=EN-US>Reference<o:p></o:p></span></b></p>

<p><span
lang=EN-US>[1] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet
allocation. J. Mach. Learn. Res.,3:993&#8211;1022, Mar. 2003.</span></p>

<p><span
lang=EN-US>[2] M. Hoffman, D. Blei, and F. Bach. Online learning for latent
dirichlet allocation. Advances in Neural Information Processing Systems,
23:856&#8211;864, 2010.</p>
-->


</body>

</html>
